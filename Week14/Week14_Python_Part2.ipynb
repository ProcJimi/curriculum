{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 14 (Part 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the current directory name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path at terminal when executing this file\n",
      "C:\\Data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Path at terminal when executing this file\")\n",
    "print(os.getcwd() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the current directory name using the Jupyter notebook magic command?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pmuhuri'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pmuhuri\\\\AppData\\\\Local\\\\Temp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TEMP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "for a in os.environ:\n",
    "    print(a, os.getenv(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "for a in os.environ:\n",
    "    print('Var: ', a, 'Value: ', os.getenv(a))\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to list all directories, subdirectories, and files from a specified directory?\n",
    "\n",
    "The following code renders a horizontal list of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets_handler.py', 'dump_data.py', 'locate_datasets.py', 'resources.tar.gz', 'spd.sas', 'support.py', 'Sysfunc.sas', '__init__.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"C:/Misc\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to list all directories, subdirectories, and files from a specified directory?\n",
    "\n",
    "The following code renders a vertical list of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_handler.py\n",
      "dump_data.py\n",
      "locate_datasets.py\n",
      "resources.tar.gz\n",
      "spd.sas\n",
      "support.py\n",
      "Sysfunc.sas\n",
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for p in os.listdir(\"C:/Misc\"):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to list all directories, subdirectories, and files from the current working directory?\n",
    "\n",
    "The following code provides a vertical list  of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_handler.py\n",
      "dump_data.py\n",
      "locate_datasets.py\n",
      "resources.tar.gz\n",
      "spd.sas\n",
      "support.py\n",
      "Sysfunc.sas\n",
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "names = os.listdir()\n",
    "for p in names:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to list all files from a specified directory but no directories or subdirectories? (Efficient method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Data\\A2_Yr2010.sas\n",
      "C:\\Data\\Create_formats.sas\n",
      "C:\\Data\\Deads_2002.sas\n",
      "C:\\Data\\Download_code.sas\n",
      "C:\\Data\\Fall2019_Take_Home_Assignment_1.sas\n",
      "C:\\Data\\New_Borns_2002.sas\n",
      "C:\\Data\\ob_visits.sas\n",
      "C:\\Data\\Read_titanic.sas\n",
      "C:\\Data\\Titanic.sas\n",
      "C:\\Data\\_1Read_Data_T.sas\n",
      "C:\\Data\\_SASCode\\FYC_16_17.sas\n",
      "C:\\Data\\_SASCode\\Longitudinal.sas\n",
      "C:\\Data\\_SASCode\\Two_set_statements.sas\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = 'C:\\\\Data\\\\'\n",
    "files = (f for f in glob.glob(path + '**/*.sas', recursive=True))\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to list all files from a specified directory but no directories or subdirectories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Data\\A2_Yr2010.sas\n",
      "C:\\Data\\adult2010.sas7bdat\n",
      "C:\\Data\\cars.sas7bdat\n",
      "C:\\Data\\catalog.sas7bcat\n",
      "C:\\Data\\Create_formats.sas\n",
      "C:\\Data\\c_deads_2002.sas7bdat\n",
      "C:\\Data\\Deads_2002.sas\n",
      "C:\\Data\\Download_code.sas\n",
      "C:\\Data\\d_2016_2017.sas7bdat\n",
      "C:\\Data\\Fall2019_Take_Home_Assignment_1.sas\n",
      "C:\\Data\\fclass.sas7bdat\n",
      "C:\\Data\\formats.sas7bcat\n",
      "C:\\Data\\fy_00.sas7bdat\n",
      "C:\\Data\\fy_01.sas7bdat\n",
      "C:\\Data\\fy_02.sas7bdat\n",
      "C:\\Data\\fy_03.sas7bdat\n",
      "C:\\Data\\fy_04.sas7bdat\n",
      "C:\\Data\\fy_05.sas7bdat\n",
      "C:\\Data\\fy_06.sas7bdat\n",
      "C:\\Data\\fy_07.sas7bdat\n",
      "C:\\Data\\fy_08.sas7bdat\n",
      "C:\\Data\\fy_09.sas7bdat\n",
      "C:\\Data\\fy_10.sas7bdat\n",
      "C:\\Data\\fy_11.sas7bdat\n",
      "C:\\Data\\fy_12.sas7bdat\n",
      "C:\\Data\\fy_13.sas7bdat\n",
      "C:\\Data\\fy_14.sas7bdat\n",
      "C:\\Data\\fy_15.sas7bdat\n",
      "C:\\Data\\h105.sas7bdat\n",
      "C:\\Data\\h113.sas7bdat\n",
      "C:\\Data\\h121.sas7bdat\n",
      "C:\\Data\\h129.sas7bdat\n",
      "C:\\Data\\h138.sas7bdat\n",
      "C:\\Data\\h147.sas7bdat\n",
      "C:\\Data\\h155.sas7bdat\n",
      "C:\\Data\\h163.sas7bdat\n",
      "C:\\Data\\h171.sas7bdat\n",
      "C:\\Data\\h181.sas7bdat\n",
      "C:\\Data\\h192.sas7bdat\n",
      "C:\\Data\\h197g.sas7bdat\n",
      "C:\\Data\\h201.sas7bdat\n",
      "C:\\Data\\h50.sas7bdat\n",
      "C:\\Data\\h60.sas7bdat\n",
      "C:\\Data\\h70.sas7bdat\n",
      "C:\\Data\\h79.sas7bdat\n",
      "C:\\Data\\h89.sas7bdat\n",
      "C:\\Data\\h97.sas7bdat\n",
      "C:\\Data\\New_Borns_2002.sas\n",
      "C:\\Data\\ob_visits.sas\n",
      "C:\\Data\\overall_hd.sas7bdat\n",
      "C:\\Data\\Read_titanic.sas\n",
      "C:\\Data\\Titanic.sas\n",
      "C:\\Data\\titanic.sas7bdat\n",
      "C:\\Data\\titanic_x.sas7bdat\n",
      "C:\\Data\\yr_2006_2016.sas7bdat\n",
      "C:\\Data\\_1Read_Data_T.sas\n",
      "C:\\Data\\Subdir2\\fclass.sas7bdat\n",
      "C:\\Data\\Subdir2\\h105.sas7bdat\n",
      "C:\\Data\\Subdir2\\h113.sas7bdat\n",
      "C:\\Data\\Subdir2\\h121.sas7bdat\n",
      "C:\\Data\\Subdir2\\h129.sas7bdat\n",
      "C:\\Data\\Subdir2\\h138.sas7bdat\n",
      "C:\\Data\\Subdir2\\h147.sas7bdat\n",
      "C:\\Data\\Subdir2\\h155.sas7bdat\n",
      "C:\\Data\\Subdir2\\h163.sas7bdat\n",
      "C:\\Data\\_SASCode\\FYC_16_17.sas\n",
      "C:\\Data\\_SASCode\\Longitudinal.sas\n",
      "C:\\Data\\_SASCode\\Two_set_statements.sas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'C:\\\\Data'\n",
    "files = []\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.sas' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "            \n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to list all directories and subdirectories from a specified directory but no files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Data\\h201ssp\n",
      "C:\\Data\\Subdir1\n",
      "C:\\Data\\Subdir2\n",
      "C:\\Data\\Week1\n",
      "C:\\Data\\Week2\n",
      "C:\\Data\\Week3\n",
      "C:\\Data\\Week4\n",
      "C:\\Data\\Week5\n",
      "C:\\Data\\_SASCode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'C:\\\\Data'\n",
    "folders = []\n",
    "for r, d, f in os.walk(path):\n",
    "    for folder in d:\n",
    "        folders.append(os.path.join(r, folder))\n",
    "            \n",
    "for f in folders:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_Name            Parent                   Created\n",
      "                      A2_Yr2010.sas           C:\\Data  Sat Nov 23 11:30:30 2019\n",
      "                 Create_formats.sas           C:\\Data  Mon Mar  4 21:09:48 2019\n",
      "                     Deads_2002.sas           C:\\Data  Mon Mar  4 21:00:54 2019\n",
      "                  Download_code.sas           C:\\Data  Mon Sep 23 05:23:34 2019\n",
      "Fall2019_Take_Home_Assignment_1.sas           C:\\Data  Thu Oct 24 12:01:18 2019\n",
      "                 New_Borns_2002.sas           C:\\Data  Mon Mar  4 21:00:54 2019\n",
      "                      ob_visits.sas           C:\\Data  Sat Sep 28 13:39:58 2019\n",
      "                   Read_titanic.sas           C:\\Data  Sun Sep  8 13:19:29 2019\n",
      "                        Titanic.sas           C:\\Data  Sat Aug 31 16:51:04 2019\n",
      "                  _1Read_Data_T.sas           C:\\Data  Sat Sep 21 07:29:19 2019\n",
      "                      FYC_16_17.sas  C:\\Data\\_SASCode  Sat Sep 28 13:55:24 2019\n",
      "                   Longitudinal.sas  C:\\Data\\_SASCode  Fri Sep 27 07:51:51 2019\n",
      "             Two_set_statements.sas  C:\\Data\\_SASCode  Thu Sep 26 23:31:05 2019\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "p = Path(\"C:/Data\")\n",
    "all_files = []\n",
    "for i in p.rglob('*.SAS'):\n",
    "    all_files.append((i.name, i.parent, time.ctime(i.stat().st_ctime)))\n",
    "\n",
    "columns = [\"File_Name\",\"Parent\", \"Created\"]\n",
    "df = pd.DataFrame.from_records(all_files, columns=columns)\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_Name                   Created\n",
      "                      A2_Yr2010.sas  Sat Nov 23 11:30:30 2019\n",
      "                 Create_formats.sas  Mon Mar  4 21:09:48 2019\n",
      "                     Deads_2002.sas  Mon Mar  4 21:00:54 2019\n",
      "                  Download_code.sas  Mon Sep 23 05:23:34 2019\n",
      "Fall2019_Take_Home_Assignment_1.sas  Thu Oct 24 12:01:18 2019\n",
      "                 New_Borns_2002.sas  Mon Mar  4 21:00:54 2019\n",
      "                      ob_visits.sas  Sat Sep 28 13:39:58 2019\n",
      "                   Read_titanic.sas  Sun Sep  8 13:19:29 2019\n",
      "                        Titanic.sas  Sat Aug 31 16:51:04 2019\n",
      "                  _1Read_Data_T.sas  Sat Sep 21 07:29:19 2019\n",
      "                      FYC_16_17.sas  Sat Sep 28 13:55:24 2019\n",
      "                   Longitudinal.sas  Fri Sep 27 07:51:51 2019\n",
      "             Two_set_statements.sas  Thu Sep 26 23:31:05 2019\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "p = Path(\"C:/Data\")\n",
    "all_files = []\n",
    "for i in p.rglob('*.SAS'):\n",
    "    all_files.append((i.name, time.ctime(i.stat().st_ctime)))\n",
    "\n",
    "columns = [\"File_Name\", \"Created\"]\n",
    "df = pd.DataFrame.from_records(all_files, columns=columns)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to select rows and columns in Pandas using [ ], .loc, iloc, .at and .iat](https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_Name\n",
      "                      A2_Yr2010.sas\n",
      "                 Create_formats.sas\n",
      "                     Deads_2002.sas\n",
      "                  Download_code.sas\n",
      "Fall2019_Take_Home_Assignment_1.sas\n",
      "                 New_Borns_2002.sas\n",
      "                      ob_visits.sas\n",
      "                   Read_titanic.sas\n",
      "                        Titanic.sas\n",
      "                  _1Read_Data_T.sas\n",
      "                      FYC_16_17.sas\n",
      "                   Longitudinal.sas\n",
      "             Two_set_statements.sas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "p = Path(\"C:/Data\")\n",
    "all_files = []\n",
    "for i in p.rglob('*.SAS'):\n",
    "    all_files.append((i.name, time.ctime(i.stat().st_ctime)))\n",
    "\n",
    "columns = [\"File_Name\", \"Created\"]\n",
    "df = pd.DataFrame.from_records(all_files, columns=columns)\n",
    "xdf=df.iloc[:,[0]]\n",
    "print(xdf.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Data\\A2_Yr2010.sas\n",
      "C:\\Data\\Create_formats.sas\n",
      "C:\\Data\\Deads_2002.sas\n",
      "C:\\Data\\Download_code.sas\n",
      "C:\\Data\\Fall2019_Take_Home_Assignment_1.sas\n",
      "C:\\Data\\New_Borns_2002.sas\n",
      "C:\\Data\\ob_visits.sas\n",
      "C:\\Data\\Read_titanic.sas\n",
      "C:\\Data\\Titanic.sas\n",
      "C:\\Data\\_1Read_Data_T.sas\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "dir =  Path('C:/Data')\n",
    "files = dir.glob('*.sas')\n",
    "for i in files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Data\\A2_Yr2010.sas\n",
      "C:/Data\\Create_formats.sas\n",
      "C:/Data\\Deads_2002.sas\n",
      "C:/Data\\Download_code.sas\n",
      "C:/Data\\Fall2019_Take_Home_Assignment_1.sas\n",
      "C:/Data\\New_Borns_2002.sas\n",
      "C:/Data\\ob_visits.sas\n",
      "C:/Data\\Read_titanic.sas\n",
      "C:/Data\\Titanic.sas\n",
      "C:/Data\\_1Read_Data_T.sas\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for name in glob.glob(\"C:/Data/*.sas\"):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "my_file = Path(\"/Data/Create_formats.sas\")\n",
    "my_file.is_file() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFGFILE ALREADY EXISTS: C:\\Users\\pmuhuri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\saspy\\sascfg_personal.py\n"
     ]
    }
   ],
   "source": [
    "from saspy import autocfg\n",
    "autocfg.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIBNAME library  'C:\\Data';\n",
      "LIBNAME new  'C:\\Data';\n",
      "data Deads_2002;\n",
      "  set new.panel6 (in=a) new.panel7 (in=b);\n",
      "  array pstats(3) pstats31 pstats42 pstats53;\n",
      "  \n",
      " if 23 in pstats then found_dead=1;\n",
      " else if 24 in pstats then found_dead=1;\n",
      " else if 31 in pstats then found_dead=1;\n",
      " else found_dead=0;  \n",
      " \n",
      "if a=1 then panel=6; else panel=7;\n",
      "if found_dead=1  then output;\n",
      " run;\n",
      " data new.c_Deads_2002; \n",
      "   set Deads_2002;\n",
      "   cum_count+count;\n",
      "run;\n",
      "\n",
      "ods pdf file='C:\\Data\\Deads_data.pdf' ;\n",
      "options nocenter nodate nonumber ls=132 leftmargin=.1in rightmargin=1in\n",
      "options nocenter ls=132;\n",
      "title 'Insope status of Deads in MEPS 2002';\n",
      "proc print data=new.c_Deads_2002 noobs;\n",
      "var Panel \n",
      "inscope INSC1231 inscop02 begrfy endrfy inscop31 pstats31 inscop42 pstats42\n",
      "        inscop53 pstats53 cum_count ;\n",
      "run;\n",
      "ods pdf close;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fd = open('C:\\Data\\Deads_2002.sas')\n",
    "print(fd.read())\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to know the pandas version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the show_versions() function to know the versions of pandas' dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.7.1.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.23.4\n",
      "pytest: 4.0.2\n",
      "pip: 18.1\n",
      "setuptools: 40.6.3\n",
      "Cython: 0.29.2\n",
      "numpy: 1.15.4\n",
      "scipy: 1.1.0\n",
      "pyarrow: None\n",
      "xarray: None\n",
      "IPython: 7.2.0\n",
      "sphinx: 1.8.4\n",
      "patsy: 0.5.1\n",
      "dateutil: 2.7.5\n",
      "pytz: 2018.7\n",
      "blosc: None\n",
      "bottleneck: 1.2.1\n",
      "tables: 3.4.4\n",
      "numexpr: 2.6.8\n",
      "feather: None\n",
      "matplotlib: 3.0.2\n",
      "openpyxl: 2.5.12\n",
      "xlrd: 1.2.0\n",
      "xlwt: 1.3.0\n",
      "xlsxwriter: 1.1.2\n",
      "lxml: 4.2.5\n",
      "bs4: 4.6.3\n",
      "html5lib: 1.0.1\n",
      "sqlalchemy: 1.2.15\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.10\n",
      "s3fs: None\n",
      "fastparquet: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)]\n",
      "\n",
      "Please wait a moment while I gather a list of all available modules...\n",
      "\n",
      "Crypto              bz2                 mistune             socketserver\n",
      "Cython              cProfile            mkl                 socks\n",
      "Downloads           calendar            mkl_fft             sockshandler\n",
      "Ex13b_Pathlib_glob  certifi             mkl_random          sortedcollections\n",
      "IPython             cffi                mmap                sortedcontainers\n",
      "OpenSSL             cgi                 mmapfile            sphinx\n",
      "PIL                 cgitb               mmsystem            sphinxcontrib\n",
      "PyQt5               chardet             modulefinder        sphinxify\n",
      "SASpy_python        chunk               more_itertools      spyder\n",
      "SDS_to_python       click               mpmath              spyder_breakpoints\n",
      "__future__          cloudpickle         msgpack             spyder_io_dcm\n",
      "_abc                clyent              msilib              spyder_io_hdf5\n",
      "_ast                cmath               msvcrt              spyder_kernels\n",
      "_asyncio            cmd                 multipledispatch    spyder_profiler\n",
      "_bisect             code                multiprocessing     spyder_pylint\n",
      "_blake2             codecs              my_cfg              sqlalchemy\n",
      "_bootlocale         codeop              navigator_updater   sqlite3\n",
      "_bz2                collections         nbconvert           sre_compile\n",
      "_cffi_backend       colorama            nbformat            sre_constants\n",
      "_codecs             colorsys            netbios             sre_parse\n",
      "_codecs_cn          commctrl            netrc               ssl\n",
      "_codecs_hk          compileall          networkx            sspi\n",
      "_codecs_iso2022     comtypes            nltk                sspicon\n",
      "_codecs_jp          concurrent          nntplib             stat\n",
      "_codecs_kr          conda               nose                statistics\n",
      "_codecs_tw          conda_build         notebook            statsmodels\n",
      "_collections        conda_env           nt                  storemagic\n",
      "_collections_abc    conda_verify        ntpath              string\n",
      "_compat_pickle      conf                ntsecuritycon       stringprep\n",
      "_compression        configparser        nturl2path          struct\n",
      "_contextvars        confuse             numba               subprocess\n",
      "_csv                contextlib          numbers             sunau\n",
      "_ctypes             contextlib2         numexpr             symbol\n",
      "_ctypes_test        contextvars         numpy               sympy\n",
      "_datetime           copy                numpydoc            sympyprinting\n",
      "_decimal            copyreg             odbc                symtable\n",
      "_distutils_findvs   crypt               odo                 sys\n",
      "_dummy_thread       cryptography        olefile             sysconfig\n",
      "_elementtree        csv                 opcode              tables\n",
      "_functools          ctypes              openpyxl            tabnanny\n",
      "_hashlib            curl                operator            tarfile\n",
      "_heapq              curses              optparse            tblib\n",
      "_imp                cwp                 os                  telnetlib\n",
      "_io                 cycler              packaging           tempfile\n",
      "_json               cython              pandas              terminado\n",
      "_locale             cythonmagic         pandas_profiling    test\n",
      "_lsprof             cytoolz             pandocfilters       test_data\n",
      "_lzma               dask                parser              test_path\n",
      "_markupbase         dataclasses         parso               test_pycosat\n",
      "_md5                datashape           partd               testpath\n",
      "_msi                datetime            past                tests\n",
      "_multibytecodec     dateutil            path                textwrap\n",
      "_multiprocessing    dbi                 pathlib             this\n",
      "_nsis               dbm                 pathlib2            threading\n",
      "_opcode             dde                 patsy               time\n",
      "_operator           decimal             pdb                 timeit\n",
      "_osx_support        decorator           pep8                timer\n",
      "_overlapped         defusedxml          perfmon             tkinter\n",
      "_pickle             difflib             pexpect             tlz\n",
      "_py_abc             dis                 phik                token\n",
      "_pydecimal          distributed         pickle              tokenize\n",
      "_pyio               distutils           pickleshare         toolz\n",
      "_pytest             doctest             pickletools         tornado\n",
      "_queue              docutils            pip                 tqdm\n",
      "_random             dummy_threading     pipes               trace\n",
      "_sha1               easy_install        pkg_resources       traceback\n",
      "_sha256             email               pkginfo             tracemalloc\n",
      "_sha3               encodings           pkgutil             traitlets\n",
      "_sha512             ensurepip           platform            tty\n",
      "_signal             entrypoints         plistlib            turtle\n",
      "_sitebuiltins       enum                pluggy              turtledemo\n",
      "_socket             errno               ply                 types\n",
      "_sqlite3            et_xmlfile          poplib              typing\n",
      "_sre                fastcache           posixpath           unicodecsv\n",
      "_ssl                faulthandler        pprint              unicodedata\n",
      "_stat               filecmp             profile             unittest\n",
      "_string             fileinput           prometheus_client   urllib\n",
      "_strptime           filelock            prompt_toolkit      urllib3\n",
      "_struct             flask               pstats              uu\n",
      "_symtable           flask_cors          psutil              uuid\n",
      "_system_path        fnmatch             pty                 venv\n",
      "_testbuffer         formatter           ptyprocess          warnings\n",
      "_testcapi           fractions           py                  wave\n",
      "_testconsole        ftplib              py_compile          wcwidth\n",
      "_testimportmultiple functools           pyclbr              weakref\n",
      "_testmultiphase     future              pycodestyle         webbrowser\n",
      "_thread             gc                  pycosat             webencodings\n",
      "_threading_local    genericpath         pycparser           werkzeug\n",
      "_tkinter            getopt              pycurl              wheel\n",
      "_tracemalloc        getpass             pydataset           widgetsnbextension\n",
      "_warnings           gettext             pydoc               win2kras\n",
      "_weakref            gevent              pydoc_data          win32api\n",
      "_weakrefset         glob                pyexpat             win32clipboard\n",
      "_win32sysloader     glob2               pyflakes            win32com\n",
      "_winapi             greenlet            pygments            win32con\n",
      "_winxptheme         gzip                pylab               win32console\n",
      "_yaml               h5py                pylint              win32cred\n",
      "abc                 hashlib             pyodbc              win32crypt\n",
      "adodbapi            heapdict            pyparsing           win32cryptcon\n",
      "afxres              heapq               pytest              win32event\n",
      "aifc                hmac                pytest_arraydiff    win32evtlog\n",
      "alabaster           html                pytest_doctestplus  win32evtlogutil\n",
      "anaconda_navigator  html5lib            pytest_openfiles    win32file\n",
      "anaconda_project    htmlmin             pytest_pylint       win32gui\n",
      "antigravity         http                pytest_remotedata   win32gui_struct\n",
      "argparse            idlelib             pythoncode          win32help\n",
      "array               idna                pythoncom           win32inet\n",
      "asn1crypto          imageio             pytz                win32inetcon\n",
      "ast                 imagesize           pywin               win32job\n",
      "astroid             imaplib             pywin32_testutil    win32lz\n",
      "astropy             imghdr              pywintypes          win32net\n",
      "asynchat            imp                 pywt                win32netcon\n",
      "asyncio             importlib           pyximport           win32pdh\n",
      "asyncore            importlib_metadata  qtawesome           win32pdhquery\n",
      "atexit              inspect             qtconsole           win32pdhutil\n",
      "atomicwrites        io                  qtpy                win32pipe\n",
      "attr                ipaddress           queue               win32print\n",
      "audioop             ipykernel           quopri              win32process\n",
      "autoreload          ipykernel_launcher  random              win32profile\n",
      "babel               ipython_genutils    rasutil             win32ras\n",
      "backcall            ipywidgets          re                  win32rcparser\n",
      "backports           isapi               regcheck            win32security\n",
      "base64              isort               regutil             win32service\n",
      "bdb                 isympy              reprlib             win32serviceutil\n",
      "binascii            itertools           requests            win32timezone\n",
      "binhex              itsdangerous        rlcompleter         win32trace\n",
      "binstar_client      jdcal               rmagic              win32traceutil\n",
      "bisect              jedi                rope                win32transaction\n",
      "bitarray            jinja2              ruamel_yaml         win32ts\n",
      "bkcharts            json                run                 win32ui\n",
      "blaze               jsonschema          runpy               win32uiole\n",
      "bleach              jupyter             sas7bdat            win32verstamp\n",
      "bokeh               jupyter_client      sas_kernel          win32wnet\n",
      "boto                jupyter_console     saslib              win_inet_pton\n",
      "bottleneck          jupyter_core        saspy               win_unicode_console\n",
      "brain_argparse      jupyterlab          sched               wincertstore\n",
      "brain_attrs         jupyterlab_server   scipy               winerror\n",
      "brain_builtin_inference keyring             scripts             winioctlcon\n",
      "brain_collections   keyword             seaborn             winnt\n",
      "brain_curses        kiwisolver          secrets             winperf\n",
      "brain_dateutil      lazy_object_proxy   select              winpty\n",
      "brain_fstrings      lib2to3             selectors           winreg\n",
      "brain_functools     libarchive          send2trash          winsound\n",
      "brain_gi            libfuturize         servicemanager      winxpgui\n",
      "brain_hashlib       libpasteurize       setuptools          winxptheme\n",
      "brain_io            linecache           shelve              wrapt\n",
      "brain_mechanize     llvmlite            shlex               wsgiref\n",
      "brain_multiprocessing locale              shutil              xdrlib\n",
      "brain_namedtuple_enum locket              signal              xlrd\n",
      "brain_nose          logging             simplegeneric       xlsxwriter\n",
      "brain_numpy         lxml                singledispatch      xlwings\n",
      "brain_pkg_resources lzma                singledispatch_helpers xlwt\n",
      "brain_pytest        macpath             sip                 xml\n",
      "brain_qt            mailbox             sipconfig           xmlrpc\n",
      "brain_random        mailcap             sipdistutils        xxsubtype\n",
      "brain_re            markupsafe          site                yaml\n",
      "brain_six           marshal             six                 zict\n",
      "brain_ssl           math                skimage             zipapp\n",
      "brain_subprocess    matplotlib          sklearn             zipfile\n",
      "brain_threading     mccabe              smtpd               zipimport\n",
      "brain_typing        menuinst            smtplib             zlib\n",
      "brain_uuid          metakernel          sndhdr              zmq\n",
      "bs4                 mimetypes           snowballstemmer     \n",
      "builtins            missingno           socket              \n",
      "\n",
      "Enter any module name to get more help.  Or, type \"modules spam\" to search\n",
      "for modules whose name or summary contain the string \"spam\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.sys.version)\n",
    "help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
